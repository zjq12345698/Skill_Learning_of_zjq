## Sobel算子、Scharr算子与Laplacian算子
### Sobel算子
Sobel算子函数：cv2.Sobel(src, ddepth, dx, dy, ksize)，返回值为Sobel算子处理后的图像。
- ddepth：图像的深度
- dx 和 dy 分别表示水平和竖直方向
- ksize 是 Sobel 算子的大小
靠近最近点的左右和上下的权重最高，所以为±2
![image](https://user-images.githubusercontent.com/129270106/230880484-e1b5b15a-11a6-4385-8230-273ca049c146.png)

```Python
img = cv2.imread('mg3.jpg', cv2.IMREAD_GRAYSCALE)

sobelx = cv2.Sobel(pie, cv2.CV_64F, 1, 0, ksize=3)  # 0,1 只算 x 方向梯度
sobelx = cv2.convertScaleAbs(sobelx) # 取负数时，取绝对值
cv_show(sobelx, 'sobelx')

sobely = cv2.Sobel(pie, cv2.CV_64F, 0, 1, ksize=3)  # 1,0 只算 y 方向梯度
sobely = cv2.convertScaleAbs(sobely) # 取负数时，取绝对值
cv_show(sobely, 'sobely')

# 分别计算 x 和 y 后，再求和（不建议直接计算，效果不好）
sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)  # 0是偏置项
cv_show(sobelxy,'sobelxy')
```
### Scharr算子
- 对结果的差异更敏感一些
- 提取的信息更多一些
![image](https://user-images.githubusercontent.com/129270106/230905051-80611a2c-bc4e-4443-a4f8-cebd021b6a2e.png)

**cv2.Scharr(src, ddepth, dx, dy, ksize)**
```Python
scharr_x = cv2.Scharr(mg3, cv2.CV_64F, 1, 0)
scharr_x = cv2.convertScaleAbs(scharr_x)
scharr_y = cv2.Scharr(mg3, cv2.CV_64F, 0, 1)
scharr_y = cv2.convertScaleAbs(scharr_y)
scharr_xy = cv2.addWeighted(scharr_x, 0.5, scharr_y, 0.5, 0)
```
### Laplacian算子
**cv2.Laplacian(src, ddepth)
- Laplacian算子用的是二阶导，对噪音点更敏感一些
- 如果中心点是边界，它与周围像素点差异的幅度会较大，Laplacian算子根据此特点可以把边界识别出来
![image](https://user-images.githubusercontent.com/129270106/230905434-92e94651-7632-46a4-aa90-24c3126db636.png)

```Python
laplacian = cv2.Laplacian(mg3, cv2.CV_64F)
laplacian = cv2.convertScaleAbs(laplacian)
```
## Canny边缘检测
Canny边缘检测流程：
- 1.使用高斯滤波器，以平滑图像，滤除噪声
- 2.计算图像中每个像素点的梯度强度和方向
- 3.应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。
- 4.应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘
- 5.通过抑制孤立的弱边缘最终完成边缘检测
### 高斯滤波器
**高斯滤波器靠近的中心点的权重比较大，较远中心点的权重比较小**
![image](https://user-images.githubusercontent.com/129270106/230907159-e24aa45b-cdce-4b12-8ee8-0344c2422e07.png)
### 梯度和方向
![image](https://user-images.githubusercontent.com/129270106/230907208-5165ef09-954c-4fa9-8e61-76c54213749f.png)
### 非极大值抑制
方法1：
  - C 点的梯度和方向可以通过前一步算出来。
  - C 点的梯度是不是一个极大值点，应该是去跟它的临近点去比较。
  - 利用 C 点梯度的方向，可以得到上面有一个交点 Q，下面有一个交点 Z，如果 C 点的梯度比 Q 和 Z 都大，那么 C 就是极大值点，其中 Q 和 Z 的梯度值通过线性差值法来计算。
  - 如果 C 的梯度是极大值点，那么 C 就是边缘点。否则 C 不是极大值点，就会被抑制。
![image](https://user-images.githubusercontent.com/129270106/230907649-99bab9bc-818e-4e04-af6e-a6c1bc5e1f9b.png)

方法2：
  - 简单计算将像素点周围固定为八个像素，当梯度角度相交的点与哪个方向近，就哪个方向的两个点。
  - 例如，梯度方向是 43° 就取上下两个像素来做极大值判断，如果梯度方向是 46°，就取左下、右上两个像素来做极大值判断。
  - 如下图所示，如果 A 的梯度值比 B 和 C 都要大，那么 A 就是边界，由于边界与梯度方向垂直，所以如下图所示黑色为边界。
![image](https://user-images.githubusercontent.com/129270106/230907877-53ec077b-d85e-48ca-b18f-a07990dd2832.png)
### 双阈值检测
- C 在 minVal 与 maxVal 之间，是候选边界，若 C 的左右或上下两边连有 A，而 A 是边界，那么定义 C 也是边界。
- B 在 minVal 与 maxVal 之间，是候选边界，若B的左右或上下像素都不是边界，那么 B 就被舍弃，不定义为边界。
![image](https://user-images.githubusercontent.com/129270106/230907977-93e64421-c950-4c39-954e-61c971b47151.png)

```Python
img = cv2.imread('mg3.jpg', cv2.IMREAD_GRAYSCALE) 

v1 = cv2.Canny(img, 80, 150)         # 第二个参数为minVal，第三个参数为maxVal
v2 = cv2.Canny(img, 50, 100)

res = np.hstack((v1, v2))
cv_show('res', res)
```
## 图像金字塔
- 金字塔的底层是比较大，越往上越小，图像金字塔就是把图像组合成金字塔的形状。
- 图像金字塔可以做图像特征提取，做特征提取时有时可能不光对原始输入做特征提取，可能还会对好几层图像金字塔做特征提取。可能每一层特征提取的结果是不一样的，再把特征提取的结果总结在一起。
常用的两种图像金字塔形式：
  - 高斯金字塔
  - 拉普拉斯金字塔
### 高斯金字塔
向下采样法（缩小）： cv2.pyrDown(src)
  - 将Gi与高斯内核卷积
  - 将所有偶数行和列去除
向上采样法（放大）: cv2.pyrUp(src)
  - 将图像每个方向扩大为原来的两倍，新增的行和列以0填充
  - 使用先前同样的内核（乘以4）与放大后的图像卷积，获取近似值
![image](https://user-images.githubusercontent.com/129270106/230909350-852ff93f-517b-4b8b-8f05-668c9b725f16.png)

```Python
img = cv2.imread('mg3.jpg')
up = cv2.pyrUp(img)
down = cv2.pyrDown(img)

```
## 拉普拉斯金字塔
- 拉普拉斯金字塔的每一层图像尺寸不变
- 拉普拉斯金字塔的每一层操作都是上一层处理后作为输入，该输入减去该输入缩小放大后的图像，获得该层的输出
![image](https://user-images.githubusercontent.com/129270106/230910120-00b4c0be-8cf2-4979-b45f-cecaccc88c15.png)

```Python
domn = cv2.pyrDown(img)
down_up = cv2.pyrUp(down)
L_1 = img - down_up
cv_show('exp', L_1)
```

## 图像轮廓
**cv2.findContours(img,mode,method)**
- 边缘有一些零零散散的线段也可以当做边缘，反正梯度上下左右发生差异，就把它当做边缘了。
- 图像的轮廓必须是一个整体，不是零零散散的，而是连在一块的。
- 为了更高的准确率，轮廓检测使用二值图像
- 图像轮廓函数：cv2.findContours(img,mode,method):
  - mode: 轮廓检索模式
    - RETR_EXTERNAL ：只检索最外面的轮廓。
    - RETR_LIST：检索所有的轮廓，并将其保存到一条链表当中。
    - RETR_CCOMP：检索所有的轮廓，并将他们组织为两层：顶层是各部分的外部边界，第二层是空洞的边界。
    - RETR_TREE：检索所有的轮廓，并重构嵌套轮廓的整个层次。( 最常用 )
  - method：轮廓逼近方法
    - CHAIN_APPROX_NONE：以Freeman链码的方式输出轮廓，如下图左所示。所有其他方法输出多边形 ( 顶点的序列 )，如下图右所示。
    - CHAIN_APPROX_SIMPLE：压缩水平的、垂直的和斜的部分，也就是，函数只保留他们的终点部分，如下图右所示。
![image](https://user-images.githubusercontent.com/129270106/230911062-4f778129-c9ac-4df1-9602-b4350ca39c73.png)

```Python
# 图像二值化
gray = cv2.cvtColor(名给, cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)        # 大于 17 的取 255，小于 127 的取 0 
```

### API
1. cv2.findContours(img，mode, method)  找出图中的轮廓值，得到的轮廓值都是嵌套格式的
- img表示输入的图片，
- mode表示轮廓检索模式，通常都使用RETR_TREE找出所有的轮廓值，
- method表示轮廓逼近方法，使用NONE表示所有轮廓都显示
2. cv2.cvtcolor(img, cv2.COLOR_BGR2GRAY)  将彩色图转换为灰度图
  - img表示输入的图片，
  - cv2.COLOR_BGR2GRAY表示颜色的变换形式
3. cv2.drawContours(img, contours, -1, (0, 0, 255), 2)  画出图片中的轮廓值，也可以用来画轮廓的近似值
  -  img表示输入的需要画的图片，
  - contours表示轮廓值，
  - -1表示轮廓的索引，
  - (0, 0, 255)表示颜色，
  - 2表示线条粗细
4. cv2.contourArea(cnt， True)   计算轮廓的面积
  - cnt为输入的单个轮廓值
5. cv2.arcLength(cnt， True)    计算轮廓的周长
6. cv2.aprroxPolyDP(cnt, epsilon， True)  用于获得轮廓的近似值，使用cv2.drawCountors进行画图操作
  - cnt为输入的轮廓值，
  - epsilon为阈值T，通常使用轮廓的周长作为阈值，
  - True表示的是轮廓是闭合的
7. x, y, w, h = cv2.boudingrect(cnt)   获得外接矩形
  - x，y, w, h 分别表示外接矩形的x轴和y轴的坐标，以及矩形的宽和高，
  - cnt表示输入的轮廓值
8. (x, y), radius = cv2.minEnclosingCircle(cnt)  获得外接圆的位置信息
  - (x, y)表示外接圆的圆心，
  - radius表示外接圆的半径，
  - cnt表示输入的轮廓
9. (x, y), radius = cv2.minEnclosingCircle(cnt)  获得外接圆的位置信息
  -  (x, y)表示外接圆的圆心，
  - radius表示外接圆的半径，
  - cnt表示输入的轮廓
10. cv2.Cricle(img, center, radius, (0, 255, 0), 2)  根据坐标在图上画出圆
  - img表示需要画的图片，
  - center表示圆的中心点，
  - radius表示圆的半径,
  - (0, 255, 0)表示颜色，
  - 2表示线条的粗细


