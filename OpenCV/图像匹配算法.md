## 模板匹配
- 模板匹配和卷积原理很像，模板在原图像上从原点开始滑动，计算模板与（图像被模板覆盖的地方）的差别程度(例如值127与值190的区别)，这个差别程度的计算方法在opencv里有6种，然后将每次计算的结果放入一个矩阵里，作为结果输出。
- 假如原图形是AxB大小，而模板是axb大小，则输出结果的矩阵是(A-a+1)x(B-b+1)。
- 模板匹配计算方式6种方式 ( 归一化效果更好 )：
  - TM_SQDIFF：计算平方不同，计算出来的值越小，越相关。
  - TM_CCORR：计算相关性，计算出来的值越大，越相关。
  - TM_CCOEFF：计算相关系数，计算出来的值越大，越相关。
  - TM_SQDIFF_NORMED：计算归一化平方不同，计算出来的值越接近0，越相关。
  - TM_CCORR_NORMED：计算归一化相关性，计算出来的值越接近1，越相关。
  - TM_CCOEFF_NORMED：计算归一化相关系数，计算出来的值越接近1，越相关。

[具体公式](https://docs.opencv.org/3.3.1/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d)

简单来讲，就是在要检测的图像上，从左到右，从上到下遍历这一幅图像，从上到下计算模板与重叠子图像的像素匹配度，如果匹配的程度越大，这说明相同的可能性越大。
### 模板匹配单个对象
**MatchTemplate(InputArray image, InputArray templ, OutputArray result, int method):**
  - image：输入一个待匹配的图像，支持8U或者32F。
  - templ：输入一个模板图像，与image相同类型。
  - result：输出保存结果的矩阵，32F类型。
  - method：要使用的数据比较方法。
  - return: 一个结果矩阵
**min_val, max_val, min_loc, max_loc = minMaxLoc(res):**
将MatchTemplate返回的结果矩阵传入， 按顺序分别得到最小值，最大值，最小值坐标，最大值坐标

**cv2.rectangle (img, pt1, pt2, color, thickness, lineType, shift)**
- *img: 源图像
- *pt1, pt2: 一条对角线的两个端点坐标
- *color: 边框颜色，通常是一个三值元组，表示一个颜色RGB三通道的值
- thickness: 框选矩形的粗细情况，默认为1像素值
- lineType: 矩形边框的线条类型，可选择CV2.LINE_8（默认）
- shift: 我们选择的将矩形移动的程度，默认为0（即不操作），可以选择一个整数n，操作将使得pt1、pt2的坐标值都除以2^n

```Python
# 1.匹配模板
template = cv2.imread("hero1.jpg")
img = cv2.imread("jh.jpg")
h, w = template.shape[:2]
res = cv2.matchTemplate(img, template, cv2.TM_SQDIFF_NORMED)

# 2.对角线坐标
min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(res)
top_left = min_loc
bottom_right = (top_left[0]+w, top_left[1]+h)

# 3.画矩形
cv2.rectangle(img, top_left, bottom_right, (124, 245, 98))
plt.subplot(121)
plt.imshow(res)
plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(img)
plt.xticks([]),plt.yticks([])
plt.suptitle("result")
plt.show()
```

